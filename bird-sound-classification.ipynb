{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cvIcZ7dYZ3A4"
   },
   "source": [
    "## Basic flow in an examplary MIR - classification research task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQSslF12Z3A_"
   },
   "source": [
    "This notebook is designed to demonstrate basic/common flow of processes in an MIR classification task: \"Automatic instrument recognition\". The content should be considered as educational material rather than research material. Various segments of it aim to raise a question for discussion rather than presenting a state-of-the-art solution. Indeed, the process has a problem that we later observe and discuss close to the end, try spotting it yourself while reading the code.\n",
    "![MIR classification task basic flow](https://raw.githubusercontent.com/MTG/MIRCourse/master/notebooks/figures/MIRresearchOverview_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SOsShVeHZ3BG"
   },
   "source": [
    "**In-class discussion topics:**\n",
    "* Defining the problem and the context, data space, reqirements, specifications <-> Literature review\n",
    "* Curating a representative research dataset (available datasets, common/standard representation formats)\n",
    "* Designing the flow, algorithms/processes/methods and implementation\n",
    "* Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C98uNhZyT5Vh"
   },
   "source": [
    "**Reading list:** https://sites.google.com/site/mirspring2018/my-reading-list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pD2Du8odZ3BJ"
   },
   "source": [
    "## A classification task: instrument recognition\n",
    "\n",
    "* Let's pick one of the standard MIR tasks: automatic instrument recognition, and limit our context as monophonic isolated notes recordings.\n",
    "* The task is a classification task; hence, our first aim is gather a set of isolated note recordings for various instruments with instrument labels. We will be using (downloading) samples from an existing recording collection ([the IOWA:MIS dataset](http://theremin.music.uiowa.edu/MIS.html))\n",
    "* Our algorithmic design will be based on the standard flow of feature extraction followed by feeding the data to a classifier  (see figure below)\n",
    "* At the end, we will use standard evaluation measures of automatic classification to test our approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8RP7NclOZ3BO"
   },
   "outputs": [],
   "source": [
    "#Basic imports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import essentia.standard as ess\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EhDMnGtEZ3BW"
   },
   "source": [
    "## Collecting raw data and investigating its nature\n",
    "\n",
    "### Downloading dataset files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYsfA0CNZ3Bh"
   },
   "source": [
    "**Collect file lists for each instrument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AfXV-LblZ3Bj",
    "outputId": "ce56cd00-090d-4774-f57e-f67efae560d3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Load metadata with correct encoding and delimiter\n",
    "metadata_path = \"notebooks/data/raw/Birds Voice.csv\"\n",
    "metadata = pd.read_csv(metadata_path, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "# Define base path for audio files\n",
    "audio_base_dir = \"notebooks/data/raw/Voice of Birds\"\n",
    "\n",
    "# Match audio files with metadata labels\n",
    "bird_files = []\n",
    "for _, row in metadata.iterrows():\n",
    "    bird_name = row[\"common_name\"]\n",
    "    bird_folder = bird_name.replace(\"/\", \"-\") + \"_sound\"\n",
    "    full_folder_path = os.path.join(audio_base_dir, bird_folder)\n",
    "    if os.path.exists(full_folder_path):\n",
    "        mp3_files = glob.glob(os.path.join(full_folder_path, \"*.mp3\"))\n",
    "        for f in mp3_files:\n",
    "            bird_files.append({\"path\": f, \"label\": bird_name})\n",
    "\n",
    "# Organize by label\n",
    "bird_files_dict = {}\n",
    "for item in bird_files:\n",
    "    label = item[\"label\"]\n",
    "    bird_files_dict.setdefault(label, []).append(item[\"path\"])\n",
    "\n",
    "print(\"âœ… Loaded bird audio files grouped by label.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFmukYMfZ3Br"
   },
   "source": [
    "Now that we have gather a small research dataset, we can now focus designing the basic flow for our classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-c6KFqRZ3Bu"
   },
   "source": [
    "![Basic flow](https://raw.githubusercontent.com/MTG/MIRCourse/master/notebooks/figures/classification_basicFlow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYZZTtYBZ3Bw"
   },
   "source": [
    "### Investigating and preprocessing raw data\n",
    "\n",
    "It is often very useful to first check a few samples from the dataset to decide what preprocessing steps are required. Let's have a look at the waveform of one sample recording for each instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "Vr2f3y2dZ3By",
    "outputId": "5320d447-0001-4ffd-a393-8c283adc7145"
   },
   "outputs": [],
   "source": [
    "# Raw-data preprocess analysis parameters\n",
    "fs = 44100\n",
    "\n",
    "num_birds = len(bird_files_dict.keys())\n",
    "print(\"Sample waveform plots\")\n",
    "plt.figure(1, figsize=(5 * num_birds, 3))\n",
    "file_ind_inlist = 0 # 0: let's take the first file in the list for sample plots\n",
    "for i,bird in enumerate(bird_files_dict.keys()):\n",
    "    sample_file = bird_files_dict[bird][file_ind_inlist]\n",
    "    x = ess.MonoLoader(filename = sample_file, sampleRate = fs)()\n",
    "    \n",
    "    plt.subplot(1,num_birds,(i+1))\n",
    "    plt.plot(x)\n",
    "    plt.title(bird)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9-kzgr1Z3B3"
   },
   "source": [
    "The recordings include a series of isolated notes for flute, violin and Eb-Clarinet and isolated notes for vibraphone. We could split the series of isolated notes to create the samples.\n",
    "\n",
    "Splitting/segmentation could be performed based on energy threshold. Below, a list of heuristically selected values are used. \n",
    "\n",
    "### Preprocessing of raw data: Segmentation, splitting, alignment,... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0oWIfJH4Z3B5"
   },
   "source": [
    "While common preprocessing steps (such as amplitude normalisation) exist, there is often some dataset and task specific preprocessing tasks required for grouping, cleaning, and format change. \n",
    "\n",
    "In the downloaded dataset, recordings include a sequence of isolated notes played in sequence which could be split into isolated notes. We would like to investigate the option of splitting using a fixed energy threshold (which would help us seperate notes using the silence regions). Let's define a function to perform this operation and visualize some samples to observe the effectiveness of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nhjFnVCLZ3B8"
   },
   "outputs": [],
   "source": [
    "# Raw-data preprocess analysis parameters\n",
    "windowSize = 4096 * 4\n",
    "hopSize = 4096 * 2\n",
    "NRG_threshold_ratio = 0.01 #threshold expressed as ratio with respect to the maximum value\n",
    "#Let's put in a container to be able to use as a single argument in function calls\n",
    "params = {\"fs\":fs, \"windowSize\":windowSize, \"hopSize\":hopSize, \"NRG_threshold_ratio\": NRG_threshold_ratio}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxgM16oZZ3CE"
   },
   "outputs": [],
   "source": [
    "#Function definition\n",
    "def split_file(filename, params):\n",
    "    '''Function to define split boundaries based on a fixed energy threshold\n",
    "    '''\n",
    "    x = ess.MonoLoader(filename = filename, sampleRate = fs)()\n",
    "    NRG = [];\n",
    "    #Main windowing and feature extraction loop\n",
    "    for frame in ess.FrameGenerator(x, frameSize = windowSize, hopSize = hopSize, startFromZero = True):\n",
    "        NRG.append(ess.Energy()(frame))\n",
    "    NRG = np.array(NRG)\n",
    "    NRG = NRG / np.max(NRG)\n",
    "    \n",
    "    #Applying energy threshold to decide wave split boundaries\n",
    "    split_decision_func = np.zeros_like(NRG)\n",
    "    split_decision_func[NRG > NRG_threshold_ratio] = 1\n",
    "    #Setting segment boundaries\n",
    "    #Inserting a zero at the beginning since we will decide the transitions using a diff function\n",
    "    split_decision_func = np.insert(split_decision_func, 0, 0)\n",
    "    diff_split_decision = np.diff(split_decision_func)\n",
    "    #Start indexes: transition from 0 to 1\n",
    "    start_indexes = np.nonzero(diff_split_decision > 0)[0] * hopSize\n",
    "    #Stop indexes: transition from 1 to 0\n",
    "    stop_indexes = np.nonzero(diff_split_decision < 0)[0] * hopSize\n",
    "    return (x, NRG, split_decision_func, start_indexes, stop_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOCdtjxHZ3CL"
   },
   "source": [
    "Let's visualize three files per instrument to check if the splits look fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "colab_type": "code",
    "id": "ajXtZE7pZ3CM",
    "outputId": "e47b8d5f-51b5-46c5-c68e-6896cfa78177"
   },
   "outputs": [],
   "source": [
    "num_birds = len(bird_files_dict.keys())\n",
    "print(\"Sample plots for waveform versus energy and splits based on energy threshold\")\n",
    "\n",
    "file_indexes = [0, 1, 2]\n",
    "for file_ind_inlist in file_indexes:\n",
    "    plt.figure(file_ind_inlist, figsize=(5 * num_birds, 3))\n",
    "    for i, bird in enumerate(bird_files_dict.keys()):\n",
    "        sample_file = bird_files_dict[bird][file_ind_inlist]\n",
    "        (x, NRG, split_decision_func, start_indexes, stop_indexes) = split_file(sample_file, params)\n",
    "        #Plotting functions for checking the split decisions\n",
    "        plt.subplot(1,num_birds,(i+1))\n",
    "        plt.title(bird)\n",
    "        plt.plot(x, label = 'sound waveform')\n",
    "        plt.plot(np.arange(NRG.size) * hopSize, NRG, 'g', label = 'NRG')\n",
    "        plt.plot(np.arange(split_decision_func.size) * hopSize, split_decision_func,'r', label = 'split function')\n",
    "        plt.vlines(start_indexes, ymin = -0.5, ymax = 0, colors='b', linestyles='solid', label='Segment start')\n",
    "        plt.vlines(stop_indexes, ymin = -0.5, ymax = 0, colors='k', linestyles='dashed', label='Segment stop')\n",
    "\n",
    "plt.legend(loc=\"best\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WYukVMTrZ3CV"
   },
   "source": [
    "The decision boundaries look fine, let's use the function to \n",
    "* get segment boundaries and crop segments, \n",
    "* amplitude normalize them and save all segments in a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6CE1UdkXZ3CY",
    "outputId": "f81bcf71-66a3-4ae7-e07e-333393e0525f"
   },
   "outputs": [],
   "source": [
    "segments_dir = os.path.join('/Users/arnaumartin/Desktop/3r_uni/Taller tecnologia musical/dataset','segments')\n",
    "if not os.path.exists(segments_dir):#creating the directory\n",
    "    os.mkdir(segments_dir)\n",
    "\n",
    "segment_files = []\n",
    "for bird, files in bird_files_dict.items():\n",
    "    file_count = 0\n",
    "    for sample_file in files:\n",
    "        x = ess.MonoLoader(filename = sample_file, sampleRate = fs)()\n",
    "        (x, NRG, split_decision_func, start_indexes, stop_indexes) = split_file(sample_file, params)\n",
    "        #Croping segments\n",
    "        for start, stop in zip(start_indexes, stop_indexes):\n",
    "            if stop - start > fs/3:#let's only keep segments larger than 1/3 second\n",
    "                x_seg = x[start: stop]\n",
    "                #Final check for amplitude (to avoid silent segments selection due to noise in split function)\n",
    "                if(np.max(np.abs(x_seg)) > 0.05):\n",
    "                    #Amplitude normalisation\n",
    "                    x_seg = x_seg / np.max(np.abs(x_seg))\n",
    "                    filename = os.path.join(segments_dir, bird + '_' + str(file_count) + '.wav')\n",
    "                    ess.MonoWriter(filename = filename, format = 'wav', sampleRate = fs)(x_seg)\n",
    "                    file_count +=1\n",
    "                    segment_files.append(filename)\n",
    "\n",
    "print(len(segment_files),'segment files created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecE-GitzZ3Cb"
   },
   "outputs": [],
   "source": [
    "#If required, you can use this cell to delete all files in a given folder\n",
    "def delete_files_in_dir(dir_name):\n",
    "    '''Deleting all files in a directory\n",
    "    ''' \n",
    "    for root, dirs, files in os.walk(dir_name):\n",
    "        for file in files:\n",
    "            file_name = os.path.join(root,file)\n",
    "            os.remove(file_name);print(file_name, 'removed');\n",
    "\n",
    "#delete_files_in_dir(segments_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmTShfNLZ3Cg"
   },
   "source": [
    "Segments saved into separate files. Check the \"data/instrument/segments/\" folder.\n",
    "\n",
    "## Feature extraction \n",
    "\n",
    "Let's compute a list of common features for each of the files and form a data frame including features and categories. We will be using the [MusicExtractor function of Essentia](https://essentia.upf.edu/documentation/reference/std_MusicExtractor.html) that would compute a large number of features commonly used in MIR literature. \n",
    "\n",
    "Let's first run it for a file and check its output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mq0W_HPVZ3Ch"
   },
   "outputs": [],
   "source": [
    "import essentia.standard as es\n",
    "\n",
    "#Running music extractor for a file:\n",
    "file = segment_files[0]#simply pick the first file in the list\n",
    "features, features_frames = es.MusicExtractor(lowlevelSilentFrames='drop',\n",
    "                                                  lowlevelFrameSize = 2048,\n",
    "                                                  lowlevelHopSize = 1024,\n",
    "                                                  lowlevelStats = ['mean', 'stdev'])(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SbPZ_i7JZ3Cn"
   },
   "source": [
    "Essentia-MusicExtractor extracts a large number of features. For simplicity, let's only keep low-level descriptors which are represented with a single scalar value as our feature set and discard other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "TvOzjojcZ3Co",
    "outputId": "3cc6950d-ee2c-4a4e-9bff-44b18d1e769a"
   },
   "outputs": [],
   "source": [
    "scalar_lowlevel_descriptors = [descriptor for descriptor in features.descriptorNames() if 'lowlevel' in descriptor and isinstance(features[descriptor], float)]\n",
    "print(\"Subset of features to be considered:\\n\",scalar_lowlevel_descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o5aBdpBtZ3Cv"
   },
   "source": [
    "Running musicextractor for all files, keeping a subset of features, writing to an output file: data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "POoJ0K8BZ3Cz",
    "outputId": "fd53a71c-1a0d-4886-e6d7-a11e5c8431d2"
   },
   "outputs": [],
   "source": [
    "#Extracting features and writing in data.csv file in the segments folder\n",
    "#  each line in the data.csv file represents a sample with features and the class information as the last element\n",
    "data_file = os.path.join(segments_dir,'data.csv')\n",
    "file_count = 0\n",
    "with open(data_file, 'w') as writer:\n",
    "    #adding column names as the first line in csv\n",
    "    line2write = ','.join(scalar_lowlevel_descriptors + ['bird']).replace('lowlevel.','') + '\\n'\n",
    "    writer.write(line2write)\n",
    "    for file in segment_files:\n",
    "        if '.wav' in file:\n",
    "            file_count +=1\n",
    "            if file_count % 20 == 0:#print name of a file every 20 files\n",
    "                print(file_count, \"files processed, current file: \",file)\n",
    "            features, features_frames = es.MusicExtractor(lowlevelSilentFrames='drop',\n",
    "                                                          lowlevelFrameSize = 2048,\n",
    "                                                          lowlevelHopSize = 1024,\n",
    "                                                          lowlevelStats = ['mean', 'stdev'])(file)\n",
    "            selected_features = [features[descriptor] for descriptor in scalar_lowlevel_descriptors]\n",
    "            bird = file.split('/')[-1].split('_')[0].lower()#class information\n",
    "            line2write = str(selected_features)[1:-1] + ',' + bird + '\\n'\n",
    "            writer.write(line2write)\n",
    "print(\"A total of \",file_count, \"files processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mMcx5G3jZ3C3"
   },
   "source": [
    "## Analysis and preprocessing of features\n",
    "\n",
    "All extracted features are saved in data.csv. Columns represent features and rows files/samples. This is a typical format in a large number of machine learning datasets (see a few of the dataset here: https://archive.ics.uci.edu/ml/index.php or other \"Data Science\" examples on the web).  \n",
    "\n",
    "***The use of a common format for data representation is beneficial in both making use of existing tools/libraries (such as Pandas) and contributing to the community with resources that are easy to use.***\n",
    "\n",
    "Let's load the data and start investigating the features. We can use Pandas (a package largely used in data science) to read data and access statistical description of the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dV84IY-RZ3C4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "CaJDBafwZ3C-",
    "outputId": "96f1c235-4ce7-4273-f18e-38681f2d3d96"
   },
   "outputs": [],
   "source": [
    "#Read data\n",
    "data = pd.read_csv(data_file)\n",
    "#Let's see the first lines of our data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZvAwtqsxZ3DD"
   },
   "source": [
    "All features are represented with columns, and the last column ('instrument') carries the class information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEnUkMmxZ3DF"
   },
   "source": [
    "Always check if your data involves NaN values and clean them (by simply removing the sample, or replacing the NaN value by a real value (such as the median of that feature))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "thpa7ESXZ3DG",
    "outputId": "f0d89c65-8400-47c7-99b8-c0604b462e51"
   },
   "outputs": [],
   "source": [
    "data.isnull().sum().sum()#sums a matrix of True/False values obtained by checking if each value is Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E34fOMf4Z3DN"
   },
   "source": [
    "**Observation:** No NaN value, proceed ..\n",
    "\n",
    "We can plot samples on two-dimensional feature spaces to check if features are discriminative for those classes. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_zrFi7BLMhai",
    "outputId": "916d739b-dabe-41fd-c3c9-9b13c7596114"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.relplot(x = \"melbands_flatness_db.mean\", y = \"spectral_centroid.mean\", hue = \"bird\", style = \"bird\", data = data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iO3pP2FOMhan"
   },
   "source": [
    "The Seaborn package includes some very useful plotting functions that facilitate such visual inspections. Here is another example: this time producing plots **for the last 6 features**, creating all combinations to form 2-dimensional feature spaces representing the samples from different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eYIDJQZfMhap",
    "outputId": "d464e659-b838-4aee-c532-3c03f4f6a676"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data.iloc[:, -7:], hue = \"bird\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ue9tdBgvMhas"
   },
   "source": [
    "As the next step, having a look at descriptive statistics of the features would be useful. Let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "4q8SmhSMZ3DP",
    "outputId": "dd3b5baa-d301-4b4c-cdba-03725281b52b"
   },
   "outputs": [],
   "source": [
    "#Descriptive statistics of the features:\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dU9u2YaDZ3DV"
   },
   "source": [
    "**Observation:** min, max, mean values of the features vary a lot, we need to normalise them. Some of the features (such as average loudness) may be irrelevant for the task (check variance of the features). For simplicity of the code here, we will keep all the features as is, but you should consider removing irrelevant features from the list.\n",
    "\n",
    "### Preprocessing of the features\n",
    "\n",
    "**Normalisation of the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "amcLwVPkZ3DX"
   },
   "outputs": [],
   "source": [
    "data_modif = data.copy()\n",
    "#Let's use sklearn's preprocessing tools for applying normalisation to features\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "data_modif.iloc[:,:84] = min_max_scaler.fit_transform(data.iloc[:,:84].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "a8-ErcHzZ3Db",
    "outputId": "50a567f2-f5ab-4234-a57f-1d59f2ca79a1"
   },
   "outputs": [],
   "source": [
    "data_modif.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UoEwUPNRZ3Dg"
   },
   "source": [
    "**Observation:** Now the features are normalised in [0,1] range, proceed to converting data into matrices that can be fed into classifiers.\n",
    "\n",
    "**IMPORTANT:** Various other preprocessing may be required based on the nature of your data. Refer to your machine learning course for preprocessing steps. We will also skip discussions on feature selection (another important topic) here and leave it to your machine learning course.\n",
    "\n",
    "We should check if our data is balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "hByJk6RnZ3Dh",
    "outputId": "024b4b18-d32e-4968-d890-b50cc75b132e"
   },
   "outputs": [],
   "source": [
    "data_modif.bird.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uxRmyFlBZ3Dl"
   },
   "source": [
    "**Observation:** our data is imbalanced, ups.... refer to your machine learning course for the problem of working with imbalanced datasets. Here, we will simply throw out some samples to balance our data\n",
    "\n",
    "### Balancing the data\n",
    "Let's simply pick 36 samples randomly from each instrument samples (since the lowest number of samples in a class is 36 (flute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "vBrUNGyqZ3Dq",
    "outputId": "d4463023-85d3-41e2-ddd8-2317400ab0ba"
   },
   "outputs": [],
   "source": [
    "min_number = data_modif.bird.value_counts()['flute']\n",
    "violin_data = data_modif[data_modif.bird == 'violin'].sample(n = min_number, random_state = 42)\n",
    "vibraphone_data = data_modif[data_modif.bird == 'vibraphone'].sample(n = min_number)\n",
    "ebclar_data = data_modif[data_modif.bird == 'ebclar'].sample(n = min_number)\n",
    "flute_data = data_modif[data_modif.bird == 'flute']\n",
    "#Merging after downsampling\n",
    "data_modif = pd.concat([ebclar_data, flute_data, violin_data, vibraphone_data])\n",
    "#Checking the balance again\n",
    "data_modif.bird.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6X3nwzjCIez"
   },
   "source": [
    "## Training an automatic classifier and testing it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tWA0Vqf6Z3Dw"
   },
   "source": [
    "**Preparing data arrays for features (inputs, X) and labels (outputs, y):**\n",
    "\n",
    "Now, we can form the input-output matrices that can be fed into classifiers. You can refer to [the tutorials of the scikit learn package](https://scikit-learn.org/stable/tutorial/index.html) to get familiar with the input-output formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "agdVdsE6Z3Dz",
    "outputId": "05c22e67-3e92-49d7-8623-82b9e026c3c9"
   },
   "outputs": [],
   "source": [
    "#input values put in a matrix, there are 84 features\n",
    "X = data_modif.iloc[:,:84].values \n",
    "#Creating output values\n",
    "data_modif.bird = pd.Categorical(data_modif.bird)#convert to categorical data\n",
    "y = np.array(data_modif.bird.cat.codes) #create label encoded outputs\n",
    "#Print the first sample\n",
    "print(\"Features of the first sample: \", X[0])\n",
    "print(\"Class of the first sample: \", y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1J5XPkyLZ3D5"
   },
   "source": [
    "Let's check content of the outputs vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Sb5rBkO4Z3D6",
    "outputId": "868bd29b-ab2e-4334-f1ad-fff48ec1bfd7"
   },
   "outputs": [],
   "source": [
    "#All output values: ebclar: 0, flute: 1, vibraphone: 2, violin: 3\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JLXjbpv-Dl93"
   },
   "source": [
    "**Splitting data into train and test subsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHS_06ejZ3D-"
   },
   "outputs": [],
   "source": [
    "#Let's split data into test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8p-JGJrwZ3EC",
    "outputId": "470d43de-04be-4a9f-9c26-2ea401dedd5a"
   },
   "outputs": [],
   "source": [
    "print(\"Size of train features matrix: \",X_train.shape, \", Size of train output vector: \",y_train.shape)\n",
    "print(\"Size of test features matrix: \",X_test.shape, \", Size of test output vector: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tr8Z2VxrZ3EE"
   },
   "source": [
    "**Defining the machine learning model and training it**\n",
    "\n",
    "Now we can train a machine learning model. Let's pick a Support Vector Machine (SVM) model and feed our data to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "RsoR_KCwZ3EG",
    "outputId": "c38900ce-120f-4993-a005-664a9b813a56"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma = 1 / (X_train.shape[-1] * X_train.var()))\n",
    "clf.fit(X_train, y_train)                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOfWFfcgZ3EJ"
   },
   "source": [
    "**Testing the model**\n",
    "\n",
    "The model is trained. Now, one can perform prediction using the model for a given set of features. If we feed the features of the test set, we expect to find the classes of the test set (true values of it are stored in y_test). We will refer to the output as \"predicted classes (y_pred).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ny-OedXEZ3EK"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ncsEtE4IZ3EN",
    "outputId": "07a0e5eb-823f-411b-8f69-dbce62766034"
   },
   "outputs": [],
   "source": [
    "#Let's check for each sample in the test set if prediction matches the true class information\n",
    "y_test == y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p54ZOy8QZ3EP",
    "outputId": "7bdc3c82-f1b7-4881-85ad-ec411378d37b"
   },
   "outputs": [],
   "source": [
    "#Data is balanced, so you can use accuracy as a measure:\n",
    "print(\"accuracy: \", np.sum(y_test == y_pred)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8As6TL7CFASc"
   },
   "source": [
    "**Observation:** the accuracy looks good but keep in mind that we have a small dataset and simply obtained a random subset for testing. **We also had an important bias !!:** we had formed our segments set by splitting larger audio files. That means a test segment may be coming from a recording which also provided some train segments. **Any other biases you spotted?**\n",
    "\n",
    "**!!! Be suspicious when you hit over 0.9 in the first run:**\n",
    "Check your code. Check if your test set represents a real life scenario and is completely independent of the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gzsrAmr3Z3ET"
   },
   "source": [
    "As the final step, let's also print the **confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "0SfE74fYZ3EU",
    "outputId": "b69d72b3-be54-45b1-ed1d-04f560a8b8ac"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "classes = np.unique(data_modif.bird)\n",
    "conf_mat = pd.DataFrame(confusion_matrix(y_test, y_pred), columns = classes, index = classes)\n",
    "conf_mat.index.name = 'Actual'\n",
    "conf_mat.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (7, 5))\n",
    "sns.set(font_scale = 1.2)\n",
    "sns.heatmap(conf_mat, cmap = \"Blues\", annot_kws = {\"size\": 12}, annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJORZSKgZ3EX"
   },
   "source": [
    "**Stand-alone use of a trained model:** \n",
    "\n",
    "Now that we have a trained model, we have the tools to perform automatic instrument classification of isolated notes. Below, you find the code to run classification on audio files. This cell does not aim testing (because it also includes the training samples) but just a demonstration of the predictions of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "G76vKdmEZ3EY",
    "outputId": "0d7d006b-dcdf-4f1d-d765-fa9b0877ef44"
   },
   "outputs": [],
   "source": [
    "#Class names dictionary\n",
    "classes = { 0: 'ebclar', 1: 'flute', 2: 'vibraphone', 3: 'violin'}\n",
    "\n",
    "#Here is the standalone function to run prediction for a given audio file\n",
    "def predict_bird(file, selected_feature_names, normalizer, classes, classifier):\n",
    "    '''Predicts the bird class for the given audio file\n",
    "    '''\n",
    "    #Extract features for a given file\n",
    "    features, features_frames = es.MusicExtractor(lowlevelSilentFrames='drop',\n",
    "                                                      lowlevelFrameSize = 2048,\n",
    "                                                      lowlevelHopSize = 1024,\n",
    "                                                      lowlevelStats = ['mean', 'stdev'])(file)\n",
    "    #Pick the features we have used in our model\n",
    "    selected_features = [features[descriptor] for descriptor in scalar_lowlevel_descriptors]\n",
    "    #Applying learned scaling to the features\n",
    "    scaled_features = min_max_scaler.transform(np.array(selected_features).reshape(1, -1))\n",
    "\n",
    "    #Running prediction\n",
    "    y_pred = classifier.predict(scaled_features)\n",
    "    #Return predicted class \n",
    "    return classes[y_pred[0]]\n",
    "#--------------------------------------------------------------------\n",
    "#Running prediction on individual files\n",
    "for file in segment_files:\n",
    "    bird_pred = predict_bird(file, scalar_lowlevel_descriptors, min_max_scaler, classes, clf)\n",
    "\n",
    "    #Printing the output\n",
    "    print(file, \" predicted as \", bird_pred)\n",
    "\n",
    "#!!! This is not a test (as it also contains training samples) but a simple demonstration \n",
    "# running standalone classifier on all files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3L5po7u2Mhbz"
   },
   "source": [
    "### Comparing classifiers\n",
    "\n",
    "Above, we have carried tests for one type of classifier. It is a common practice to compare performances of various classifiers with various settings. Below, we provide an example of such comparison on a limited set of classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FeBmncj9Mhb0",
    "outputId": "4a182db4-22cc-42bf-e39a-e2ae10ab6383"
   },
   "outputs": [],
   "source": [
    "#Edited version of https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')#suppress warnings\n",
    "#importing various classifiers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma = 1 / (X_train.shape[-1] * X_train.var())),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    GaussianNB()]\n",
    "\n",
    "names = [\"KNN\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\"Neural Net\", \"Naive Bayes\"]\n",
    "\n",
    "#Creating empty list of scores for each classifier, we will append test results to these lists \n",
    "scores = {}\n",
    "for name in names:\n",
    "    scores[name] = []\n",
    "\n",
    "#Let's split our data into test and train\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = 0.20, random_state = 1)\n",
    "\n",
    "#Let's run 10 random experiments, collect scores for each classifier \n",
    "num_tests = 10\n",
    "for iteration_number in range(num_tests):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 1/num_tests, random_state = iteration_number)\n",
    "    #normalisation of the data (learned from training data, applied to test data)\n",
    "    scaler = StandardScaler().fit(x_train)\n",
    "    norm_x_train = scaler.transform(x_train)\n",
    "    norm_x_val = scaler.transform(x_val)\n",
    "    \n",
    "    # test over each classifier\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(norm_x_train, y_train)#train\n",
    "        score = clf.score(norm_x_val, y_val)#test\n",
    "        scores[name].append(score)\n",
    "\n",
    "for name, score in scores.items():\n",
    "    print(\"{0}: acc = {1:1.2f}, +-{2:1.2f},\\tvalues: {3}\".format(name, np.mean(score), np.std(score), np.around(score, decimals = 2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "injD39y2Mhb5"
   },
   "source": [
    "Following this comparison, you can pick the classifier with highest performance, and report its performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jB8xAE-Mhb6",
    "outputId": "2c1ba599-4f60-49b4-bff7-ee65b114e59e"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train_val)\n",
    "norm_x_train_val = scaler.transform(X_train_val)\n",
    "norm_x_test = scaler.transform(X_test)\n",
    "selected_model = SVC(kernel=\"linear\", C=0.025)#Linear SVM performance is high, let's pick that one\n",
    "selected_model.fit(norm_x_train_val,y_train_val)\n",
    "y_pred = selected_model.predict(norm_x_test)\n",
    "print(\"Number of test samples: \", len(y_pred))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3KlNl7fUMhb9"
   },
   "source": [
    "<img src=https://miro.medium.com/max/974/1*CNWo23_VnUJPXdfrqbiB0g.jpeg width=\"400\">\n",
    "\n",
    "<img src=https://www.oreilly.com/library/view/python-data-analysis/9781785282287/graphics/B04223_10_02.jpg width=\"250\">"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lecture1_IntroWithACaseStudy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
